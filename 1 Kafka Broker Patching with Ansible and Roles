Kafka Broker Patching with Ansible and Roles

Objective:
Patch Kafka brokers across a cluster of servers by performing the following steps:
Stop the Kafka broker service.
Update or patch the Kafka installation.
Start the Kafka broker service.
Ensure the Kafka broker is running correctly after the patch.
Steps:
Ansible Inventory: Defines the Kafka broker nodes in your cluster.
Ansible Roles: Roles handle tasks such as stopping Kafka, patching Kafka, and starting Kafka, ensuring a modular and reusable approach.
Example Directory Structure:
The Ansible project will have the following structure:

css
Copy code
.
├── ansible.cfg
├── inventory
├── playbook.yml
└── roles
    ├── kafka_patch
    │   ├── tasks
    │   │   ├── main.yml
    │   │   ├── stop_kafka.yml
    │   │   ├── patch_kafka.yml
    │   │   └── start_kafka.yml
    │   └── handlers
    │       └── main.yml
    └── common
        └── tasks
            └── install_java.yml
1. Define ansible.cfg (Optional)
ini
Copy code
[defaults]
inventory = ./inventory
remote_user = ubuntu
private_key_file = ~/.ssh/id_rsa
host_key_checking = False
2. Define the inventory file
The inventory file contains the list of Kafka broker nodes:

ini
Copy code
[kafka_brokers]
broker1 ansible_host=192.168.1.10
broker2 ansible_host=192.168.1.11
broker3 ansible_host=192.168.1.12
3. Create the kafka_patch Role
The Kafka patching process will be split into multiple tasks, and each task will be modular, like stopping Kafka, applying the patch, and restarting Kafka.

a) Main Task File: roles/kafka_patch/tasks/main.yml
The main task file calls specific task files for stopping, patching, and restarting Kafka.

yaml
Copy code
---
# roles/kafka_patch/tasks/main.yml
- include_tasks: stop_kafka.yml
- include_tasks: patch_kafka.yml
- include_tasks: start_kafka.yml
b) Stop Kafka Broker Task: roles/kafka_patch/tasks/stop_kafka.yml
This task stops the Kafka broker on the target machine:

yaml
Copy code
---
# roles/kafka_patch/tasks/stop_kafka.yml
- name: Stop Kafka broker service
  service:
    name: kafka
    state: stopped
  become: yes
  notify: "Check Kafka status"
Explanation: Uses the service module to stop the Kafka service. It also includes a notification to trigger the handler that checks Kafka status after restarting.
c) Patch Kafka Task: roles/kafka_patch/tasks/patch_kafka.yml
This task handles the patching or updating of Kafka:

yaml
Copy code
---
# roles/kafka_patch/tasks/patch_kafka.yml
- name: Download the latest Kafka package
  get_url:
    url: https://archive.apache.org/dist/kafka/latest/kafka_2.13-2.8.0.tgz
    dest: /tmp/kafka.tgz
  become: yes

- name: Extract the Kafka package
  unarchive:
    src: /tmp/kafka.tgz
    dest: /opt/kafka
    remote_src: yes
  become: yes

- name: Update Kafka binaries
  command: cp -r /opt/kafka/kafka_2.13-2.8.0/* /opt/kafka/
  become: yes
Explanation:
The get_url module downloads the latest Kafka package.
The unarchive module extracts the downloaded Kafka tarball.
Finally, the command module copies the new binaries to the Kafka installation directory.
d) Start Kafka Broker Task: roles/kafka_patch/tasks/start_kafka.yml
This task starts the Kafka broker after the patch is applied:

yaml
Copy code
---
# roles/kafka_patch/tasks/start_kafka.yml
- name: Start Kafka broker service
  service:
    name: kafka
    state: started
  become: yes
Explanation: Uses the service module to start the Kafka broker.
4. Create Handlers for Post-Patch Validation
a) Create Handler: roles/kafka_patch/handlers/main.yml
This handler will be used to validate the status of Kafka after the patch:

yaml
Copy code
---
# roles/kafka_patch/handlers/main.yml
- name: Check Kafka status
  command: systemctl status kafka
  become: yes
  register: kafka_status
  ignore_errors: yes

- name: Fail if Kafka is not running
  fail:
    msg: "Kafka service is not running"
  when: kafka_status.rc != 0
Explanation:
The first task checks if the Kafka service is running after the patch.
If the service is not running (rc != 0), it triggers a failure with an appropriate message.
5. Common Role: Install Java
Kafka requires Java, so we can use a common role to ensure Java is installed on the server.

Install Java Task: roles/common/tasks/install_java.yml
yaml
Copy code
---
# roles/common/tasks/install_java.yml
- name: Install OpenJDK 11
  apt:
    name: openjdk-11-jdk
    state: present
  become: yes
Explanation: This installs OpenJDK 11 using the apt module.
6. Create the Playbook
The main playbook, playbook.yml, ties together the common role and the Kafka patch role:

yaml
Copy code
---
# playbook.yml
- hosts: kafka_brokers
  become: yes
  roles:
    - common
    - kafka_patch
Explanation: The playbook first ensures Java is installed using the common role, and then it runs the kafka_patch role to patch the Kafka brokers.
7. Running the Playbook
To execute the playbook and patch Kafka brokers across your cluster, use the following command:

bash
Copy code
ansible-playbook playbook.yml
Summary of the Workflow:
Ansible Inventory defines the Kafka broker nodes.
Common Role ensures Java is installed before patching Kafka (if needed).
Kafka Patch Role stops the Kafka service, downloads the latest Kafka version, applies the patch, and restarts the service.
Handlers validate the Kafka service status after patching.
Modularity: Each task (stop, patch, start) is separated into specific task files, which makes the playbook easier to manage and reusable.
Key Benefits of Using Ansible for Kafka Patching:
Automation: Manual intervention is minimized, reducing the risk of human error.
Modular Design: The roles and tasks are reusable and can be adapted for different environments.
Consistency: All Kafka brokers are patched using the same process, ensuring consistent results across the cluster.
Zero Downtime: If needed, you can introduce rolling updates by updating brokers one by one, ensuring minimal downtime for Kafka clusters.
